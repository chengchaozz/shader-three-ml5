<html>

<head>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/three.js/r71/three.min.js"></script>
  <script src="https://unpkg.com/ml5@0.4.3/dist/ml5.min.js"></script>
  <video id="video" width="640" height="480" autoplay style="display: none"></video>
  <style>
    /* We want our scene to span the entire window */
    body {
      margin: 0;
    }
  </style>
</head>

<body>

  <script id="fragShader" type="shader-code">
		uniform vec2 res;
		uniform sampler2D bufferTexture;
		uniform vec3 smokeSource;
		uniform float time;
		void main() {
	        vec2 pixel = gl_FragCoord.xy / res.xy;
	        
	        float dist = distance(smokeSource.xy,gl_FragCoord.xy);
	        
	        gl_FragColor = texture2D( bufferTexture, pixel );

	        
			gl_FragColor.rgb += smokeSource.z * max(15.0-dist,0.0);

		//	vec2 smokePoint = vec2(res.x/2.0+100.0*sin(time),res.y/2.0+1.*cos(time*3.5)*20.0);
		//	dist = distance(smokePoint,gl_FragCoord.xy);
		//	gl_FragColor.rgb += 0.01 * max(15.0-dist,0.0);


	        float xPixel = 1.0/res.x;//The size of a single pixel
	        float yPixel = 1.0/res.y;
	        vec4 rightColor = texture2D(bufferTexture,vec2(pixel.x+xPixel,pixel.y));
	        vec4 leftColor = texture2D(bufferTexture,vec2(pixel.x-xPixel,pixel.y));
	        vec4 upColor = texture2D(bufferTexture,vec2(pixel.x,pixel.y+yPixel));
	        vec4 downColor = texture2D(bufferTexture,vec2(pixel.x,pixel.y-yPixel));
	        //Handle the bottom boundary
		 	if(pixel.y <= yPixel){
		 		downColor.rgb = vec3(0.0);
		 	}
	        
	        float factor = 8.0 * 0.016 * (leftColor.r + rightColor.r + downColor.r * 3.0 + upColor.r - 6.0 * gl_FragColor.r);
		 
	        
	        float minimum = 0.003;
			if(factor >= -minimum && factor < 0.0) factor = -minimum;

			gl_FragColor.rgb += factor;
		 	
		 }
	</script>
  <script>
    //@author Omar Shehata. 2015.
    //We are loading the Three.js library from the cdn here: http://cdnjs.com/libraries/three.js/
    var scene;
    var camera;
    var renderer;
    var x,y,px,py;

  const scale = (num, in_min, in_max, out_min, out_max) => {
    return (num - in_min) * (out_max - out_min) / (in_max - in_min) + out_min;
  }
    //ML5//////////////////////////////////////////////////
  var video = document.getElementById('video');
  // var canvas = document.getElementById('canvas');
  //var ctx = canvas.getContext('2d');

  // The detected positions will be inside an array
  let poses = [];

  // Create a webcam capture
  if (navigator.mediaDevices && navigator.mediaDevices.getUserMedia) {
    navigator.mediaDevices.getUserMedia({ video: true }).then(function (stream) {
      video.srcObject = stream;
      video.play();
    });
  }


  function drawCameraIntoCanvas() {
    // Draw the video element into the canvas
   // ctx.drawImage(video, 0, 0, 640, 480);
    // We can call both functions to draw all keypoints and the skeletons
    drawKeypoints();
   // drawSkeleton();
    window.requestAnimationFrame(drawCameraIntoCanvas);
  }
  // Loop over the drawCameraIntoCanvas function
  drawCameraIntoCanvas();

  // Create a new poseNet method with a single detection
  const poseNet = ml5.poseNet(video, modelReady);
  poseNet.on('pose', gotPoses);

  // A function that gets called every time there's an update from the model
  function gotPoses(results) {
    poses = results;
  }

  function modelReady() {
    console.log("model ready")
    poseNet.multiPose(video)
  }

  // A function to draw ellipses over the detected keypoints
  function drawKeypoints() {
    // Loop through all the poses detected
    for (let i = 0; i < poses.length; i++) {
      // For each pose detected, loop through all the keypoints
      for (let j = 0; j < poses[i].pose.keypoints.length; j++) {
        let keypoint = poses[i].pose.keypoints[j];
        // Only draw an ellipse is the pose probability is bigger than 0.2
       // console.log(poses[i].pose.keypoints[0].position.x)
        
        if (keypoint.score > 0.8) {
          x = poses[i].pose.keypoints[0].position.x;
          y = poses[i].pose.keypoints[0].position.y;
         
        }
      }
    }
  }


    function scene_setup() {
      //This is the basic scene setup
      scene = new THREE.Scene();
      var width = window.innerWidth;
      var height = window.innerHeight;
      //Note that we're using an orthographic camera here rather than a prespective
      camera = new THREE.OrthographicCamera(width / - 2, width / 2, height / 2, height / - 2, 1, 1000);
      camera.position.z = 2;

      renderer = new THREE.WebGLRenderer();
      renderer.setSize(window.innerWidth, window.innerHeight);
      document.body.appendChild(renderer.domElement);
    }

    ////////////////////////////////

    var bufferScene;
    var textureA;
    var textureB;
    var bufferMaterial;
    var plane;
    var bufferObject;
    var finalMaterial;
    var quad;

    function buffer_texture_setup() {
      //Create buffer scene
      bufferScene = new THREE.Scene();
      //Create 2 buffer textures
      textureA = new THREE.WebGLRenderTarget(window.innerWidth, window.innerHeight, { minFilter: THREE.LinearFilter, magFilter: THREE.NearestFilter });
      textureB = new THREE.WebGLRenderTarget(window.innerWidth, window.innerHeight, { minFilter: THREE.LinearFilter, magFilter: THREE.NearestFilter });
      //Pass textureA to shader
      bufferMaterial = new THREE.ShaderMaterial({
        uniforms: {
          bufferTexture: { type: "t", value: textureA },
          res: { type: 'v2', value: new THREE.Vector2(window.innerWidth, window.innerHeight) },//Keeps the resolution
          smokeSource: { type: "v3", value: new THREE.Vector3(0, 0, 0) },
          time: { type: "f", value: Math.random() * Math.PI * 2 + Math.PI }
        },
        fragmentShader: document.getElementById('fragShader').innerHTML
      });
      plane = new THREE.PlaneBufferGeometry(window.innerWidth, window.innerHeight);
      bufferObject = new THREE.Mesh(plane, bufferMaterial);
      bufferScene.add(bufferObject);

      //Draw textureB to screen 
      finalMaterial = new THREE.MeshBasicMaterial({ map: textureB });
      quad = new THREE.Mesh(plane, finalMaterial);
      scene.add(quad);
    }

    //Initialize the Threejs scene
    scene_setup();

    //Setup the frame buffer/texture we're going to be rendering to instead of the screen
    buffer_texture_setup();



    //Send position of smoke source with value
    var mouseDown = false;
    function UpdateMousePosition(X, Y) {
      var mouseX = X;
      var mouseY = window.innerHeight - Y;
     //  bufferMaterial.uniforms.smokeSource.value.x = mouseX;
     //  bufferMaterial.uniforms.smokeSource.value.y = mouseY;
    }
    document.onmousemove = function (event) {
      UpdateMousePosition(event.clientX, event.clientY)
    }

    document.onmousedown = function (event) {
      mouseDown = true;
      bufferMaterial.uniforms.smokeSource.value.z = 0.1;
    }
    document.onmouseup = function (event) {
      mouseDown = false;
      bufferMaterial.uniforms.smokeSource.value.z = 0;
    }

    //Render everything!
    function render() {

      requestAnimationFrame(render);

      //Draw to textureB
      renderer.render(bufferScene, camera, textureB, true);

      //Swap textureA and B
      var t = textureA;
      textureA = textureB;
      textureB = t;
      quad.material.map = textureB;
      bufferMaterial.uniforms.bufferTexture.value = textureA;

      //Update time
      bufferMaterial.uniforms.time.value += 0.01;
      bufferMaterial.uniforms.smokeSource.value.x = scale(x,650,-15,0, window.innerWidth);
      bufferMaterial.uniforms.smokeSource.value.y = scale(y,350,40,0,window.innerHeight/2.);
      let dist= Math.sqrt((x-px) * (x-px) + (y-py) * (y-py));
      let average=[];
      let sumX=0,averX;
      let sumY=0,averY;
      if(average.length>=8){
        average.shift();
        average.push({ x: bufferMaterial.uniforms.smokeSource.value.x, y: bufferMaterial.uniforms.smokeSource.value.y })
      }else{
      average.push({x: bufferMaterial.uniforms.smokeSource.value.x, y: bufferMaterial.uniforms.smokeSource.value.y})
      }
      for(let i=0;i<average.length;i++){
        sumX+=average[i].x;
        sumY+= average[i].y;
      }
      averX= sumX/average.length
      averY=sumY/average.length
      bufferMaterial.uniforms.smokeSource.value.x = averX
      bufferMaterial.uniforms.smokeSource.value.y = averY
     bufferMaterial.uniforms.smokeSource.value.z = scale(dist, 8, 15, 0.09, 0.15);
      


      px=x;
      py=y;

      //Finally, draw to the screen
      renderer.render(scene, camera);
    }
    render();


  </script>
</body>

</html>